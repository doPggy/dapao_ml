{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个例子比较简单，利用 knn 算法给手写体分类，分成 0 - 9 的数字。\n",
    "\n",
    "训练集和测试集分部都很有规律。首先文件名以 num_order 方式命名，num 代表这个是什么数字，order 代表是类别为 num 的第 order 个样例。\n",
    "\n",
    "而一个文件内部用 0 1 数字模拟像素点构成一个 32 X 32 的图像。\n",
    "\n",
    "在这个例子里，吧 32 X 32 flatten 了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((3,3))\n",
    "y = np.ones((1,3))\n",
    "np.append(x, y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# flatten\n",
    "def img_to_vector(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "#         img_vec = np.zeros((1, 32 * 32))\n",
    "        img_vec = np.array([])\n",
    "        lines   = f.readlines()\n",
    "#         print(len(lines)) # 32\n",
    "#         print(len(lines[0])) # 33 多了一个 \\n\n",
    "        for line in lines:\n",
    "            img_vec = np.append(img_vec, list(map(int, line[0:32])))\n",
    "        return img_vec\n",
    "\n",
    "# 归一化不用做了，因为值只有 0,1 不存在某个值过大影响距离权重\n",
    "def pre_handle():\n",
    "    list_train_dirs = os.listdir('./trainingDigits')\n",
    "    \n",
    "    # shape = (m, 1024) m 为例子个数\n",
    "    train_sample_num      = len(list_train_dirs)\n",
    "    x_train               = np.zeros((train_sample_num, 1024))\n",
    "    y_train               = np.zeros((train_sample_num))\n",
    "    \n",
    "    i = 0\n",
    "    for train_file in list_train_dirs:\n",
    "        vec           = img_to_vector('./trainingDigits' + '/' + train_file)\n",
    "        x_train[i, :] = vec\n",
    "        filename, extension = os.path.splitext(train_file)\n",
    "        class_name    = filename.split('_')[0] # 0_0\n",
    "        y_train[i]    = int(class_name)\n",
    "        i            += 1\n",
    "    # 准备测试集\n",
    "    i = 0\n",
    "    list_test_dirs  = os.listdir('./testDigits')\n",
    "    test_sample_num = len(list_test_dirs)\n",
    "    x_test          = np.zeros((test_sample_num, 1024))\n",
    "    y_test          = np.zeros((test_sample_num))\n",
    "    for test_file in list_test_dirs:\n",
    "        vec           = img_to_vector('./testDigits' + '/' + test_file)\n",
    "        x_test[i, :]  = vec\n",
    "        filename, extension = os.path.splitext(test_file)\n",
    "        class_name    = filename.split('_')[0] # 0_0\n",
    "        y_test[i]     = int(class_name)\n",
    "        i            += 1\n",
    "    return x_train, y_train, x_test, y_test\n",
    "            \n",
    "x_train, y_train, x_test, y_test = pre_handle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936\n",
      "0.9894291754756871\n"
     ]
    }
   ],
   "source": [
    "def knn(sample, x_train, y_train, k):\n",
    "    sq        = (x_train - sample) ** 2\n",
    "    distances = (sq.sum(axis = 1)) ** 0.5 # 为什么是 1？保留每个计算的距离\n",
    "    # 按照距离从小到大排序\n",
    "    sort_index = distances.argsort()\n",
    "    # 求前 k 个最小距离中，类别最多的\n",
    "    class_count = {}\n",
    "    for i in range(k):\n",
    "        index = sort_index[i]\n",
    "        label = y_train[index]\n",
    "        class_count[label] = class_count.get(label, 0) + 1\n",
    "    # 用 dict 的 key-value 元组根据 value 逆序排序\n",
    "    res = sorted(class_count.items(), key = itemgetter(1), reverse = True)\n",
    "#     print(res)\n",
    "    return res[0][0] # 最多的类别\n",
    "        \n",
    "def hand_write(x_train, y_train, x_test, y_test, k):\n",
    "    x_test_len = len(x_test)\n",
    "    correct    = 0\n",
    "    for i in range(x_test_len):\n",
    "        pre_class = knn(x_test[i], x_train, y_train, k)\n",
    "#         print(pre_class, y_test[i])\n",
    "        if pre_class == y_test[i]:\n",
    "            correct += 1\n",
    "    print(correct)\n",
    "    return correct / x_test_len\n",
    "\n",
    "print(hand_write(x_train, y_train, x_test, y_test, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([23,1,222]).argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不得不说正确率是很高的。但是它的问题就是效率实在太低，每一个要预测的数据放进去，就要和模型内已有的数据做运算，只要模型中数据庞大起来，它的运算就要久。\n",
    "\n",
    "900 多个待预测样本，每个样本要计算 1000+ 次，这样就是 1000 * 900 次计算。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
