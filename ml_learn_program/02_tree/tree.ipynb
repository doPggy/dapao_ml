{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "from functools import reduce\n",
    "import operator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[[1, 1, true],\n",
    "[1, 1, true],\n",
    "[1, 2, false],\n",
    "...\n",
    "]\n",
    "'''\n",
    "# 计算信息熵\n",
    "# 主要是第 k 类样本的信息，本实例中的类别只有两个，true or false\n",
    "\n",
    "# def _calc(p1, p2):\n",
    "#     return p1 * log(p1, 2) - p2 * log(p2, 2)\n",
    "\n",
    "\n",
    "def calc_ent(data_set):\n",
    "    set_size = len(data_set)\n",
    "#     data_set[:, -1]\n",
    "    feat = {}\n",
    "    # 统计 k 类样本，对应的数量\n",
    "    for data in data_set:\n",
    "        label = data[-1]\n",
    "        feat[label] = feat.get(label, 0) + 1\n",
    "    ent = 0.0\n",
    "#     def _c(x, y):\n",
    "#         x_p = x * 1.0 / set_size\n",
    "#         y_p = y * 1.0 / set_size\n",
    "#         print(x_p, y_p)\n",
    "#         return x_p * log(x_p, 2) - y_p * log(y_p, 2)\n",
    "    # 信息熵公式\n",
    "    # \n",
    "    for label in feat:\n",
    "        p    = float(feat[label]) / set_size\n",
    "        ent -= p * log(p, 2)\n",
    "    return ent\n",
    "#     return reduce(lambda x, y : x * 1.0 / set_size - y * 1.0 / set_size, feat.values())\n",
    "    # insert 影响元数据\n",
    "#     need_reduce = list(feat.values())\n",
    "#     need_reduce.insert(0, 0)\n",
    "#     print(need_reduce)\n",
    "#     return reduce(_c, need_reduce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "       ]\n",
    "labels = ['no surface', 'flippers']\n",
    "calc_ent(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5219280948873621"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'none'],\n",
    "       ]\n",
    "calc_ent(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 2, 33]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = [1, 2, 33]\n",
    "\n",
    "dd = d[:]\n",
    "dd[0] = 22\n",
    "d\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此可见，分类多了，信息越混乱，熵越高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 属性 - feat 色泽\n",
    "# 属性值 - feat_value 乌黑\n",
    "def split_data_set_by_feat(data_set, feat, feat_value):\n",
    "    split_data_set = []\n",
    "    for data in data_set:\n",
    "        if data[feat] == feat_value:\n",
    "            reduced = data[:feat]\n",
    "            reduced.extend(data[feat + 1:])\n",
    "            split_data_set.append(reduced) # 把指定属性剔除了\n",
    "    return split_data_set\n",
    "\n",
    "\n",
    "# 找到最好的划分方式\n",
    "def find_best_feat_split(data_set):\n",
    "    sample_num = len(data_set)\n",
    "    base_ent   = calc_ent(data_set)\n",
    "    feat_num   = len(data_set[0]) - 1 # 属性个数\n",
    "    max_gain   = -1\n",
    "    best_feat  = -1\n",
    "    gain       = 0.0\n",
    "    for i in range(feat_num):\n",
    "        feat_values      = [ example[i] for example in data_set ]\n",
    "        feat_unique_vals = set(feat_values) # 统计属性值有几种\n",
    "        sub_ent          = 0.0\n",
    "        gain             = 0.0\n",
    "        # 根据属性与拥有的属性值进行划分 计算总的信息熵\n",
    "        for feat_value in feat_unique_vals:\n",
    "            sub_sample = split_data_set_by_feat(data_set, i, feat_value)\n",
    "#             print(sub_sample)\n",
    "            sub_ent   += len(sub_sample) * 1.0 / sample_num * calc_ent(sub_sample)\n",
    "        # 计算信息增益，找最大的增益的属性划分\n",
    "        gain = base_ent - sub_ent\n",
    "        if gain > max_gain:\n",
    "            max_gain  = gain\n",
    "            best_feat = i\n",
    "    return best_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "       ]\n",
    "find_best_feat_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classList, 所有样本的类别值\n",
    "def majority(class_list):\n",
    "    c = {}\n",
    "    for class_ in class_list:\n",
    "        c[class_] = c.get(class_, 0) + 1\n",
    "    sorted_count = sorted(c.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    return sorted_count[0][0]\n",
    "\n",
    "# 在西瓜书中\n",
    "def create_tree(data_set, feat_names):\n",
    "    class_list = [ exa[-1] for exa in data_set ]\n",
    "    # 递归终止条件\n",
    "    # 所有样本都属于一个类别 k\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return class_list[0] # 返回这个类别\n",
    "    # 属性集为空\n",
    "    if len(data_set[0]) == 1:\n",
    "        return majority(class_list)\n",
    "    \n",
    "#     print(data_set)\n",
    "    best_feat      = find_best_feat_split(data_set)\n",
    "    best_feat_name = feat_names[best_feat]\n",
    "    # 样本集中会把对应属性剔除，所以对应的名字也要删除\n",
    "    del(feat_names[best_feat])\n",
    "    node          = { best_feat_name : {} }\n",
    "    feat_values   = set([ exa[best_feat] for exa in data_set ])\n",
    "    for feat_value in feat_values:\n",
    "        sub_feat_names = feat_names[:]\n",
    "        node[best_feat_name][feat_value] = create_tree(split_data_set_by_feat(data_set, best_feat, feat_value), sub_feat_names)\n",
    "    return node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [[1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "       ]\n",
    "labels = ['no surface', 'flippers']\n",
    "tree = create_tree(test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其实就是 n 叉树的遍历，对于每一个节点遍历，而不是考虑多个。\n",
    "def classify(input_tree, feats, test_vec):\n",
    "    # 当前节点代表一种属性划分，而 key 是属性 {'no surface': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
    "    # { key:value} 一个 dict 代表一个节点，同时 key 代表分支，value 是其指向的元素，可以是节点，也可以是值\n",
    "#     classify_branchs = input_tree.keys()\n",
    "    # 当前属性划分\n",
    "    cur_attr_split   = list(input_tree.keys())[0]\n",
    "    print(cur_attr_split)\n",
    "    print(feats)\n",
    "    cur_attr_index   = feats.index(cur_attr_split.strip())\n",
    "    classify_branch_nodes = input_tree[cur_attr_split]\n",
    "    for feat_value in classify_branch_nodes.keys():\n",
    "        if test_vec[cur_attr_index] == feat_value:\n",
    "            if type(classify_branch_nodes[feat_value]) == dict:\n",
    "                return classify(classify_branch_nodes[feat_value], feats, test_vec)\n",
    "            else:\n",
    "                return classify_branch_nodes[feat_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no surface\n",
      "['no surface', 'flippers']\n",
      "flippers\n",
      "['no surface', 'flippers']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(tree, ['no surface', 'flippers'], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.333333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = {\n",
    "    1:1,\n",
    "    3:3,\n",
    "    2:33,\n",
    "}\n",
    "# aa.items()\n",
    "aa.values()\n",
    "sum(map(lambda x : x * 1.0 / 3, aa.values()))\n",
    "# reduce(lambda x, y : x - y, aa.values())\n",
    "# reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)\n",
    "# 37 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = {}\n",
    "b.get(True, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1,2,True],\n",
    "    [3, 3, True],\n",
    "    [3, 3, True],\n",
    "    [3, 3, False],\n",
    "])\n",
    "\n",
    "np.sum(a[:,-1] == False)# 最后一行\n",
    "#a[:][-1] 具体到某一行\n",
    "# a[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tear_rate': {'normal': {'astigmatic': {'yes': {'prescript': {'hyper': {'age': {'presbyopic': 'no lenses',\n",
       "        'pre': 'no lenses',\n",
       "        'young': 'hard'}},\n",
       "      'myope': 'hard'}},\n",
       "    'no': {'age': {'presbyopic': {'prescript': {'hyper': 'soft',\n",
       "        'myope': 'no lenses'}},\n",
       "      'pre': 'soft',\n",
       "      'young': 'soft'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备隐形眼镜数据\n",
    "with open('./lenses.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    x_train = [ line.strip().split('\\t') for line in lines ]\n",
    "#     class_  = list(set([line.strip().split('\\t')[-1] for line in lines]))\n",
    "#     print(x_train)\n",
    "feat_names  = ['age', 'prescript', 'astigmatic', 'tear_rate']\n",
    "lenses_tree = create_tree(data_set = x_train, feat_names = feat_names)\n",
    "lenses_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
