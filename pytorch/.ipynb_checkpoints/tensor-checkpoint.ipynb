{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般 ML/DL 一开始都需要数据预处理，将原始数据变成张量。\n",
    "\n",
    "而且可以利用 `t.cuda()` 将张量复制到 `GPU` 上运算\n",
    "\n",
    "接下来提到的都是 `pytorch` 提供的张量类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三个属性，可以知晓\n",
    "\n",
    "同时两个张量之间的运算，要保持 `dtype，device` 一致。\n",
    "\n",
    "不过在 1.3 已经可以整形和浮点型运算了。还是看文档靠谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.strided\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(t.device('cuda:0'))\n",
    "print(t1.layout)\n",
    "print(t1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用 data 创建张量\n",
    "\n",
    "用 python 的 list 也可以创阿金，但是用 numpy.ndarray 偏多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1, 2, 3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = t.Tensor(data) # 构造函数\n",
    "t2 = t.tensor(data) # 工厂方法函数\n",
    "t3 = t.as_tensor(data) # 工厂方法函数\n",
    "t4 = t.from_numpy(data) # 工厂方法函数\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不用 data 创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.eye(2) #创建对角矩阵，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.zeros(2, 2) # 创建 0 矩阵，参数为每个轴上的长度\n",
    "t.zeros([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9643, 0.1530],\n",
       "        [0.3676, 0.7016]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.ones(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytorch` 的 `dtype` 会根据操作系统不同而有不同的默认 `dtype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量创建的四种方法的区别\n",
    "\n",
    "## t.Tensor(), t.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "t1 = t.Tensor(data) # 构造函数\n",
    "t2 = t.tensor(data) # 工厂方法函数\n",
    "t3 = t.as_tensor(data) # 工厂方法函数\n",
    "t4 = t.from_numpy(data) # 工厂方法函数\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)\n",
    "print(t.get_default_dtype()) # 获得默认 dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensor` 是构造方法，得到的张量会根据默认 `dtype`,也指定不了 `dtype`。\n",
    "\n",
    "而 `t.tensor` 等其他创建方法都是工厂方法，得到的张量的数据类型根据传入的 `data` 数据类型而定。\n",
    "\n",
    "相比之下可能工厂方法的创建方法更灵活。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享内存与拷贝内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old [1 2 3]\n",
      "new [0 0 0]\n",
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([0, 0, 0], dtype=torch.int32)\n",
      "tensor([0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print('old', data)\n",
    "data[0] = 0\n",
    "data[1] = 0\n",
    "data[2] = 0\n",
    "print('new', data)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改了源头数据，`as_tensor,from_numpy` 方式创建的张量的数据也被修改。\n",
    "\n",
    "说明他们俩，都和源数据共享内存。\n",
    "\n",
    "而 `Tensor, tensor` 方式都是拷贝内存。 \n",
    "\n",
    "共享内存方式程序执行效率更高。但程序不复杂的时候没有必要利用这个特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "[0, 2, 3]\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3]\n",
    "t5 = t.as_tensor(l)\n",
    "print(t5)\n",
    "l[0] = 0\n",
    "print(l)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`as_tensor` 方法对 `numpy.ndarray` 共享内存，不对 `python` 内建数据类型共享。例如上述例子 `list`\n",
    "\n",
    "当然还要注意，`numpy.ndarray` 是在 CPU 上工作，如果 `as_tensor` 在 `GPU` 上，需要将 `numpy.ndarray` 拷贝到 `GPU`\n",
    "\n",
    "所以一般说来最好的创建方式是 `tensor` 省去共享内存方式时，需要注意的数据变动，而且数据类型可以控制。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
